{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ccs/home/fwang2/.conda/envs/wm1/lib/python3.6/site-packages/numpy/__init__.py\n",
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "print(np.__file__)\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h34n18']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = !echo $(cat ${LSB_DJOB_HOSTFILE} | sort | uniq | grep -v login | grep -v batch) \n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infiniband hardware address can be incorrect! Please read BUGS section in ifconfig(8).\n",
      "Infiniband hardware address can be incorrect! Please read BUGS section in ifconfig(8).\n",
      "h34n18\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "!ifconfig | grep -Eo 'inet (addr:)?([0-9]*\\.){3}[0-9]*' | grep -Eo '([0-9]*\\.){3}[0-9]*' | grep -v '127.0.0.1'\n",
    "!ifconfig | sed -En 's/127.0.0.1//;s/.*inet (addr:)?(([0-9]*\\.){3}[0-9]*).*/\\2/p'\n",
    "!hostname\n",
    "!echo $PMIX_RANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h34n18.summit.olcf.ornl.gov:2222']\n"
     ]
    }
   ],
   "source": [
    "# Set up TF_CONFIG on this rank\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "nodes_list = str(nodes[0]).split(' ')\n",
    "comp_nodes = nodes_list[:]\n",
    "for i in range(len(nodes_list)):\n",
    "    comp_nodes[i] += \".summit.olcf.ornl.gov:2222\"\n",
    "print(comp_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "os.environ['TF_CONFIG'] = json.dumps({\n",
    "    'cluster': {\n",
    "        'worker': comp_nodes\n",
    "    }, \n",
    "    'task': {'type': 'worker', 'index': 0}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"cluster\": {\"worker\": [\"h34n18.summit.olcf.ornl.gov:2222\"]}, \"task\": {\"type\": \"worker\", \"index\": 0}}\n",
      "Fri Jun 26 19:44:03 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.116.00   Driver Version: 418.116.00   CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000004:04:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    49W / 300W |  15751MiB / 16130MiB |      0%   E. Process |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000004:05:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    49W / 300W |    599MiB / 16130MiB |      0%   E. Process |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000004:06:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    50W / 300W |    599MiB / 16130MiB |      0%   E. Process |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000035:03:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    49W / 300W |    599MiB / 16130MiB |      0%   E. Process |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000035:04:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    48W / 300W |    599MiB / 16130MiB |      0%   E. Process |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000035:05:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    50W / 300W |    599MiB / 16130MiB |      0%   E. Process |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0    163952      C   .../home/fwang2/.conda/envs/wm1/bin/python 15741MiB |\n",
      "|    1    163952      C   .../home/fwang2/.conda/envs/wm1/bin/python   589MiB |\n",
      "|    2    163952      C   .../home/fwang2/.conda/envs/wm1/bin/python   589MiB |\n",
      "|    3    163952      C   .../home/fwang2/.conda/envs/wm1/bin/python   589MiB |\n",
      "|    4    163952      C   .../home/fwang2/.conda/envs/wm1/bin/python   589MiB |\n",
      "|    5    163952      C   .../home/fwang2/.conda/envs/wm1/bin/python   589MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# !jsrun -n2 -a1 -g6 -c42 python setup_tfconfig.py\n",
    "!echo $TF_CONFIG\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
