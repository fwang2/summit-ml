{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596328230899",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Using PyTorch\n",
    "\n",
    "This note is built on top of the general\n",
    "[linear regression](Linear-Regression.ipynb) discussion, but using PyTorch to solve it.\n",
    "\n",
    "1. Define variable\n",
    "2. Construct loss function and optimizer\n",
    "3. Training cycle: forward, backward, update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch = 0, loss = 11.40568733215332\nepoch = 10, loss = 0.21087977290153503\nepoch = 20, loss = 0.1795072704553604\nepoch = 30, loss = 0.1553146243095398\nepoch = 40, loss = 0.13438305258750916\nepoch = 50, loss = 0.11627233028411865\nepoch = 60, loss = 0.10060252249240875\nepoch = 70, loss = 0.08704439550638199\nepoch = 80, loss = 0.07531355321407318\nepoch = 90, loss = 0.06516359746456146\nepoch = 100, loss = 0.05638158321380615\nepoch = 110, loss = 0.04878309369087219\nepoch = 120, loss = 0.04220858961343765\nepoch = 130, loss = 0.03652017563581467\nepoch = 140, loss = 0.03159845992922783\nepoch = 150, loss = 0.027339929714798927\nepoch = 160, loss = 0.02365538850426674\nepoch = 170, loss = 0.020467448979616165\nepoch = 180, loss = 0.017709001898765564\nepoch = 190, loss = 0.015322397463023663\nepoch = 200, loss = 0.013257416896522045\nepoch = 210, loss = 0.011470727622509003\nepoch = 220, loss = 0.009924815967679024\nepoch = 230, loss = 0.008587276563048363\nepoch = 240, loss = 0.007430000230669975\nepoch = 250, loss = 0.006428670138120651\nepoch = 260, loss = 0.0055622803047299385\nepoch = 270, loss = 0.004812673665583134\nepoch = 280, loss = 0.004164050333201885\nepoch = 290, loss = 0.00360286608338356\nepoch = 300, loss = 0.0031172942835837603\nepoch = 310, loss = 0.0026972133200615644\nepoch = 320, loss = 0.002333695301786065\nepoch = 330, loss = 0.0020191846415400505\nepoch = 340, loss = 0.0017470545135438442\nepoch = 350, loss = 0.0015115991700440645\nepoch = 360, loss = 0.001307890983298421\nepoch = 370, loss = 0.0011316256131976843\nepoch = 380, loss = 0.00097911327611655\nepoch = 390, loss = 0.0008471686160191894\nepoch = 400, loss = 0.0007329903310164809\nepoch = 410, loss = 0.000634217809420079\nepoch = 420, loss = 0.0005487351445481181\nepoch = 430, loss = 0.00047478702617809176\nepoch = 440, loss = 0.00041080242954194546\nepoch = 450, loss = 0.0003554379509296268\nepoch = 460, loss = 0.00030753217288292944\nepoch = 470, loss = 0.0002660860773175955\nepoch = 480, loss = 0.00023022863024380058\nepoch = 490, loss = 0.00019920503837056458\ninput is 4, y_pred = {model.forward(newx).data}\n"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x_data = torch.Tensor([[1.0, 2.0, 3.0]]).T\n",
    "y_data = torch.Tensor([[2.0, 4.0, 6.0]]).T\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1) # A linear model, one in and one out\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        forward accept an input, return an output\n",
    "        we can use any model, but here, we just use pre-defined torch.nn.Linear\n",
    "        which is assigned in the self.linear\n",
    "        \"\"\"\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred \n",
    "\n",
    "model = Model()\n",
    "\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# training loop\n",
    "\n",
    "for epoch in range(500):\n",
    "    # forward pass\n",
    "    y_pred = model(x_data)\n",
    "\n",
    "    # compute and print loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"epoch = {epoch}, loss = {loss.data}\")\n",
    "\n",
    "    # zero gradient\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()  # update \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "input is 4, y_pred = 7.984797954559326\n"
    }
   ],
   "source": [
    "\n",
    "# after training\n",
    "newx = Variable(torch.Tensor([[4.0]]))\n",
    "print(f\"input is 4, y_pred = {model.forward(newx).data[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}